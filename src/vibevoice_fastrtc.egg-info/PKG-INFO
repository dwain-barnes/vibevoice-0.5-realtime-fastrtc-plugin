Metadata-Version: 2.4
Name: vibevoice-fastrtc
Version: 0.1.0
Summary: FastRTC-compatible wrapper for Microsoft VibeVoice-Realtime-0.5B TTS
Author: FastRTC Community
License: MIT
Project-URL: Homepage, https://github.com/your-username/vibevoice-fastrtc
Project-URL: Documentation, https://github.com/your-username/vibevoice-fastrtc#readme
Project-URL: Repository, https://github.com/your-username/vibevoice-fastrtc
Project-URL: Issues, https://github.com/your-username/vibevoice-fastrtc/issues
Keywords: tts,text-to-speech,fastrtc,vibevoice,realtime,streaming
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Multimedia :: Sound/Audio :: Speech
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.24.0
Requires-Dist: torch>=2.0.0
Requires-Dist: transformers>=4.40.0
Requires-Dist: huggingface-hub>=0.20.0
Provides-Extra: fastrtc
Requires-Dist: fastrtc>=0.0.10; extra == "fastrtc"
Requires-Dist: gradio>=4.0.0; extra == "fastrtc"
Provides-Extra: vibevoice
Requires-Dist: vibevoice@ git+https://github.com/microsoft/VibeVoice.git ; extra == "vibevoice"
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Provides-Extra: all
Requires-Dist: vibevoice-fastrtc[dev,fastrtc,vibevoice]; extra == "all"
Dynamic: license-file

# VibeVoice-FastRTC

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)

A FastRTC-compatible wrapper for [Microsoft VibeVoice-Realtime-0.5B](https://huggingface.co/microsoft/VibeVoice-Realtime-0.5B), enabling real-time text-to-speech with ~300ms first-chunk latency.

## Features

- **FastRTC Protocol Compatible**: Implements the `TTSModel` protocol for seamless integration
- **Real-time Streaming**: ~300ms latency to first audio chunk
- **Multiple Voices**: 7 English voices + experimental multilingual support
- **Flexible Output**: Supports both `float32` and `int16` audio formats
- **Async & Sync**: Both `stream_tts` (async) and `stream_tts_sync` generators

## Installation

### Quick Install

```bash
pip install vibevoice-fastrtc
```

### With FastRTC Support

```bash
pip install vibevoice-fastrtc[fastrtc]
```

### Full Installation (includes VibeVoice)

```bash
# Clone and install VibeVoice first
git clone https://github.com/microsoft/VibeVoice.git
cd VibeVoice
pip install -e .
cd ..

# Then install this wrapper
pip install vibevoice-fastrtc[fastrtc]
```

### From Source

```bash
git clone https://github.com/your-username/vibevoice-fastrtc.git
cd vibevoice-fastrtc
pip install -e .[all]
```

## Quick Start

### Basic Usage

```python
from vibevoice_tts import VibeVoiceTTS, VibeVoiceOptions

# Initialize the model
model = VibeVoiceTTS()

# Configure options
options = VibeVoiceOptions(
    speaker_name="Emma",  # Available: Carter, Davis, Emma, Frank, Grace, Mike, Samuel
    cfg_scale=1.5,        # Expressiveness (0.0-3.0)
    ddpm_steps=5,         # Quality/speed tradeoff (2-10)
)

# Generate complete audio
sample_rate, audio = model.tts("Hello, world!", options)
print(f"Generated {len(audio)/sample_rate:.2f}s of audio at {sample_rate}Hz")
```

### Streaming (Sync)

```python
for sample_rate, chunk in model.stream_tts_sync("This is streaming TTS!", options):
    # Process each audio chunk in real-time
    play_audio(chunk, sample_rate)
```

### Streaming (Async)

```python
async for sample_rate, chunk in model.stream_tts("Async streaming!", options):
    await process_audio(chunk, sample_rate)
```

## FastRTC Integration

### Echo Bot Example

```python
from fastrtc import Stream, ReplyOnPause, get_stt_model
from vibevoice_tts import VibeVoiceTTS, VibeVoiceOptions

# Initialize models
tts_model = VibeVoiceTTS()
stt_model = get_stt_model()
options = VibeVoiceOptions(speaker_name="Emma")

def echo(audio):
    """Echo back what the user says."""
    text = stt_model.stt(audio)
    for chunk in tts_model.stream_tts_sync(text, options):
        yield chunk

# Create and launch the stream
stream = Stream(
    ReplyOnPause(echo), 
    mode="send-receive", 
    modality="audio"
)
stream.ui.launch()
```

### LLM Voice Chat

```python
from fastrtc import Stream, ReplyOnPause, get_stt_model
from vibevoice_tts import VibeVoiceTTS, VibeVoiceOptions
import anthropic

# Initialize
tts = VibeVoiceTTS()
stt = get_stt_model()
client = anthropic.Anthropic()
options = VibeVoiceOptions(speaker_name="Mike", cfg_scale=1.5)

def voice_chat(audio):
    """Voice chat with Claude."""
    # Transcribe user speech
    user_text = stt.stt(audio)
    
    # Get LLM response
    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=150,
        messages=[{"role": "user", "content": user_text}]
    )
    assistant_text = response.content[0].text
    
    # Stream TTS response
    for chunk in tts.stream_tts_sync(assistant_text, options):
        yield chunk

stream = Stream(ReplyOnPause(voice_chat), mode="send-receive", modality="audio")
stream.ui.launch()
```

## Configuration Options

### VibeVoiceOptions

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `speaker_name` | str | "Emma" | Voice preset to use |
| `cfg_scale` | float | 1.5 | Classifier-Free Guidance (0.0-3.0) |
| `ddpm_steps` | int | 5 | Diffusion steps (2-10, more = slower but higher quality) |
| `chunk_size` | int | 50 | Tokens per streaming chunk |

### Available Speakers

**English:**
- Carter, Davis, Emma, Frank, Grace, Mike

**Indian English:**
- Samuel

**Experimental Multilingual:**
- German, French, Italian, Japanese, Korean, Dutch, Polish, Portuguese, Spanish

## Hardware Requirements

- **GPU Recommended**: NVIDIA GPU with 2GB+ VRAM for real-time performance
- **CPU Fallback**: Works on CPU but significantly slower
- **Tested Hardware**: NVIDIA T4, RTX 3060, Mac M4 Pro achieve real-time

## API Reference

### VibeVoiceTTS

```python
class VibeVoiceTTS:
    def __init__(
        self,
        model_path: str = "microsoft/VibeVoice-Realtime-0.5B",
        device: str | None = None,  # Auto-detect if None
        output_format: str = "float32",  # or "int16"
        voices_dir: str | None = None,
    ): ...
    
    def tts(
        self, 
        text: str, 
        options: VibeVoiceOptions | None = None
    ) -> tuple[int, np.ndarray]: ...
    
    async def stream_tts(
        self, 
        text: str, 
        options: VibeVoiceOptions | None = None
    ) -> AsyncGenerator[tuple[int, np.ndarray], None]: ...
    
    def stream_tts_sync(
        self, 
        text: str, 
        options: VibeVoiceOptions | None = None
    ) -> Generator[tuple[int, np.ndarray], None, None]: ...
    
    def get_available_speakers(self) -> dict[str, list[str]]: ...
```

## Troubleshooting

### Model Not Found
```bash
# Ensure VibeVoice is installed
pip install git+https://github.com/microsoft/VibeVoice.git
```

### CUDA Out of Memory
```python
# Use smaller DDPM steps
options = VibeVoiceOptions(ddpm_steps=2)

# Or force CPU
model = VibeVoiceTTS(device="cpu")
```

### Voice Presets Not Found
Voice presets are automatically downloaded on first use. If you're offline, pre-download them:
```python
from huggingface_hub import snapshot_download
snapshot_download("microsoft/VibeVoice-Realtime-0.5B")
```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- [Microsoft VibeVoice](https://github.com/microsoft/VibeVoice) - The underlying TTS model
- [FastRTC](https://fastrtc.org/) - Real-time communication framework
- [VibeVoice Community](https://github.com/vibevoice-community/VibeVoice) - Community fork with additional features

## Links

- [FastRTC Documentation](https://fastrtc.org/)
- [VibeVoice HuggingFace](https://huggingface.co/microsoft/VibeVoice-Realtime-0.5B)
- [VibeVoice Technical Report](https://arxiv.org/abs/2508.19205)
- [FastRTC TTS Gallery](https://fastrtc.org/text_to_speech_gallery/)
